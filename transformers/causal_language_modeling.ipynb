{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://huggingface.co/docs/transformers/en/tasks/language_modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ELI5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koyonakayama/workspace/hugging_face_tutorial/.env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/koyonakayama/workspace/hugging_face_tutorial/.env/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for eli5_category contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/eli5_category\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 4.17k/4.17k [00:00<00:00, 5.95MB/s]\n",
      "Downloading readme: 100%|██████████| 12.6k/12.6k [00:00<00:00, 4.63MB/s]\n",
      "Downloading data: 100%|██████████| 62.3M/62.3M [00:06<00:00, 9.61MB/s]\n",
      "Downloading data: 100%|██████████| 5.00M/5.00M [00:00<00:00, 8.89MB/s]\n",
      "Downloading data: 100%|██████████| 1.76M/1.76M [00:00<00:00, 3.56MB/s]\n",
      "Downloading data: 100%|██████████| 3.85M/3.85M [00:00<00:00, 9.59MB/s]\n",
      "Generating train split: 100%|██████████| 91772/91772 [00:08<00:00, 10780.52 examples/s]\n",
      "Generating validation1 split: 100%|██████████| 5446/5446 [00:00<00:00, 11182.69 examples/s]\n",
      "Generating validation2 split: 100%|██████████| 2375/2375 [00:00<00:00, 12623.92 examples/s]\n",
      "Generating test split: 100%|██████████| 5411/5411 [00:00<00:00, 11753.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "eli5 = load_dataset(\"eli5_category\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = eli5.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '74elki',\n",
       " 'title': 'If cabin pressure during a flight is controlled, why do our ears do the thing?',\n",
       " 'selftext': '',\n",
       " 'category': 'Physics',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dnxo6rk', 'dnxqu5p'],\n",
       "  'text': [\"Cabin pressure is equalized at about 7000 feet it also changes slower than the actual speed of the ascent. So from 0-7000 and 7000-0 you still experience changes in pressure (but less quickly than if the cabin wasn't pressurized at all) Edit - [image I found while searching for the same thing a while back]( URL_0 )\",\n",
       "   'Friend of mine flys a medical jet that keeps the pressure even lower, 2-3000ft I think. Then there are some outrageously expensive flights.'],\n",
       "  'score': [5, 3],\n",
       "  'text_urls': [['https://i.stack.imgur.com/BWHWi.jpg'], []]},\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '74elki',\n",
       " 'title': 'If cabin pressure during a flight is controlled, why do our ears do the thing?',\n",
       " 'selftext': '',\n",
       " 'category': 'Physics',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers.a_id': ['dnxo6rk', 'dnxqu5p'],\n",
       " 'answers.text': [\"Cabin pressure is equalized at about 7000 feet it also changes slower than the actual speed of the ascent. So from 0-7000 and 7000-0 you still experience changes in pressure (but less quickly than if the cabin wasn't pressurized at all) Edit - [image I found while searching for the same thing a while back]( URL_0 )\",\n",
       "  'Friend of mine flys a medical jet that keeps the pressure even lower, 2-3000ft I think. Then there are some outrageously expensive flights.'],\n",
       " 'answers.score': [5, 3],\n",
       " 'answers.text_urls': [['https://i.stack.imgur.com/BWHWi.jpg'], []],\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5 = eli5.flatten()\n",
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer([\" \".join(x) for x in examples[\"answers.text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1091 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4):  25%|██▌       | 1000/4000 [00:01<00:03, 822.41 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2111 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4): 100%|██████████| 4000/4000 [00:01<00:00, 2694.26 examples/s]\n",
      "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1526 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4):  25%|██▌       | 250/1000 [00:00<00:00, 764.28 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Map (num_proc=4): 100%|██████████| 1000/1000 [00:00<00:00, 2285.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_eli5 = eli5.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=eli5[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "\n",
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 4000/4000 [00:02<00:00, 1553.73 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 1000/1000 [00:00<00:00, 3562.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 500/3864 [13:23<1:28:08,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9982, 'grad_norm': 4.384872913360596, 'learning_rate': 1.74120082815735e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1000/3864 [34:53<1:15:53,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.9498, 'grad_norm': 4.060859680175781, 'learning_rate': 1.4824016563146998e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1288/3864 [43:28<1:26:20,  2.01s/it]\n",
      " 33%|███▎      | 1288/3864 [45:20<1:26:20,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8219423294067383, 'eval_runtime': 111.9973, 'eval_samples_per_second': 24.867, 'eval_steps_per_second': 3.116, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1500/3864 [51:02<57:13,  1.45s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8997, 'grad_norm': 3.799984931945801, 'learning_rate': 1.2236024844720498e-05, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2000/3864 [1:04:19<40:33,  1.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8546, 'grad_norm': 3.95866060256958, 'learning_rate': 9.648033126293997e-06, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 2500/3864 [1:18:09<34:28,  1.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8638, 'grad_norm': 4.06355619430542, 'learning_rate': 7.060041407867495e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2576/3864 [1:20:28<31:23,  1.46s/it]  \n",
      " 67%|██████▋   | 2576/3864 [1:22:25<31:23,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.81364107131958, 'eval_runtime': 116.452, 'eval_samples_per_second': 23.915, 'eval_steps_per_second': 2.997, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3000/3864 [1:34:10<24:03,  1.67s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8212, 'grad_norm': 4.162864685058594, 'learning_rate': 4.472049689440994e-06, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 3500/3864 [1:47:56<11:13,  1.85s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.819, 'grad_norm': 4.005804061889648, 'learning_rate': 1.884057971014493e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3864/3864 [1:58:35<00:00,  1.82s/it]\n",
      "100%|██████████| 3864/3864 [2:00:33<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8118786811828613, 'eval_runtime': 117.648, 'eval_samples_per_second': 23.672, 'eval_steps_per_second': 2.966, 'epoch': 3.0}\n",
      "{'train_runtime': 7233.4878, 'train_samples_per_second': 4.271, 'train_steps_per_second': 0.534, 'train_loss': 3.8797500010109345, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3864, training_loss=3.8797500010109345, metrics={'train_runtime': 7233.4878, 'train_samples_per_second': 4.271, 'train_steps_per_second': 0.534, 'total_flos': 1009062726598656.0, 'train_loss': 3.8797500010109345, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_eli5_clm-model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [01:43<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity: 45.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Somatic hypermutation allows the immune system to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"my_awesome_eli5_clm-model/checkpoint-3500\")\n",
    "outputs = model.generate(inputs, max_new_tokens=100, do_sample=True, top_k=50, top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Somatic hypermutation allows the immune system to control this kind of damage. The immune system has no reason to control your own body. Instead, the immune system is essentially a small group of small cells in your body that are actually being damaged by your immune system. Because your body has no such cells to deal with each attack, this immune system is able to do so by changing the immune system's machinery. For example, if an echidna dies of the attacks, it will die of the same type of disease as the case of a\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
